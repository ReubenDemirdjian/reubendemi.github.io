<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Reuben Demirdjian</title>
    <link>http://localhost:1313/website/</link>
    <description>Recent content on Reuben Demirdjian</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>ReubenDemi@gmail.com (Reuben Demirdjian)</managingEditor>
    <webMaster>ReubenDemi@gmail.com (Reuben Demirdjian)</webMaster>
    <lastBuildDate>Wed, 23 Jul 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/website/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>WISER/Womanium Talk</title>
      <link>http://localhost:1313/website/wiser_womanium_talk/</link>
      <pubDate>Wed, 23 Jul 2025 00:00:00 +0000</pubDate><author>ReubenDemi@gmail.com (Reuben Demirdjian)</author>
      <guid>http://localhost:1313/website/wiser_womanium_talk/</guid>
      <description>&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [[&#39;$&#39;,&#39;$&#39;]],
    displayMath: [[&#39;$$&#39;,&#39;$$&#39;]],
    processEscapes: true,
    processEnvironments: true,
    skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;],
    TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; },
         extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] }
  }
});
&lt;/script&gt;
&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
  MathJax.Hub.Queue(function() {
    // Fix &lt;code&gt; tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
    }
});
&lt;/script&gt;
&lt;p&gt;I gave this talk on July 14th, 2025 as a part of the &lt;a href=&#34;https://www.thewiser.org/&#34;&gt;WISER/Womanium&lt;/a&gt; Quantum Program. I also recommend checking out the other talks on their channel because there are truly some amazing ones on there!&lt;/p&gt;</description>
      <content:encoded><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<p>I gave this talk on July 14th, 2025 as a part of the <a href="https://www.thewiser.org/">WISER/Womanium</a> Quantum Program. I also recommend checking out the other talks on their channel because there are truly some amazing ones on there!</p>
<p>The intent of this talk is to provide a bird&rsquo;s-eye view of a particular methodology for using quantum computers to solve nonlinear differential equations, and some of the challenges that come along with it. I hope that you enjoy!</p>
<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share; fullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/v_FzYD7HjoQ?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" title="YouTube video"></iframe>
    </div>

]]></content:encoded>
    </item>
    <item>
      <title>CV</title>
      <link>http://localhost:1313/website/cv/</link>
      <pubDate>Mon, 26 May 2025 13:36:46 -0700</pubDate><author>ReubenDemi@gmail.com (Reuben Demirdjian)</author>
      <guid>http://localhost:1313/website/cv/</guid>
      <description>&lt;div class=&#34;container&#34; style=&#34;display: flex; align-items: flex-start;&#34;&gt;
    &lt;div class=&#34;text&#34; style=&#34;flex: 1; padding-right: 20px;&#34;&gt;
		&lt;h2 style=&#34;margin-bottom: 10px;&#34;&gt;
			&lt;span style=&#34;color:#3498db;&#34;&gt;Reuben Demirdjian&lt;/span&gt;
		&lt;/h2&gt;
		&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
			&lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;Contact&lt;/b&gt;: ReubenDemi at gmail dot com&lt;/div&gt;
		&lt;/div&gt;
		&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
			&lt;div style=&#34;text-align: left;&#34;&gt;&lt;a href=&#34;https://scholar.google.com/citations?user=jUAkP-kAAAAJ&amp;hl=en&#34;&gt;Google Scholar&lt;/a&gt;&lt;/div&gt;
		&lt;/div&gt;
		&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
			&lt;div style=&#34;text-align: left;&#34;&gt;&lt;a href=&#34;https://www.linkedin.com/in/reuben-demirdjian/&#34;&gt;LinkedIn&lt;/a&gt;&lt;/div&gt;
		&lt;/div&gt;
    &lt;/div&gt;
    &lt;img src=&#34;Headshot_circle.png&#34; style=&#34;max-width: 25%; height: auto; margin-top: 30px; margin-right: 30px;&#34;&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;h3 style=&#34;margin-bottom: 10px;&#34;&gt;
    &lt;span style=&#34;color:#3498db;&#34;&gt;Education&lt;/span&gt;
&lt;/h3&gt;
&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
    &lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;PhD in Oceanography&lt;/b&gt;, University of California, San Diego&lt;/div&gt;
    &lt;div style=&#34;text-align: right;&#34;&gt;Sept 2014 – May 2020&lt;/div&gt;
&lt;/div&gt;
&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
    &lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;Bsc in Mathematics&lt;/b&gt;, University of California, Santa Barbara&lt;/div&gt;
    &lt;div style=&#34;text-align: right;&#34;&gt;Sept 2010 – June 2012&lt;/div&gt;
&lt;/div&gt;
&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
    &lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;Bsc in Physics&lt;/b&gt;, University of California, Santa Barbara&lt;/div&gt;
    &lt;div style=&#34;text-align: right;&#34;&gt;Sept 2010 – June 2012&lt;/div&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;h3 style=&#34;margin-bottom: 10px;&#34;&gt;
    &lt;span style=&#34;color:#3498db;&#34;&gt;Work Experience&lt;/span&gt;
&lt;/h3&gt;
&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
    &lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;Research Meteorologist&lt;/b&gt; – U.S. Naval Research Laboratory&lt;/div&gt;
    &lt;div style=&#34;text-align: right;&#34;&gt;July 2023 – Present&lt;/div&gt;
&lt;/div&gt;
&lt;ul style=&#34;margin-top: 0; padding: 0; margin-left: 40px;&#34;&gt;
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Develop and optimize quantum algorithms to solve differential equations&lt;/li&gt;
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Supervise a postdoc developing algorithms with end-to-end resource analysis&lt;/li&gt;
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Weather model development for high-performance computers&lt;/li&gt;
	&lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Dynamical and statistical analysis of weather model data&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
    &lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;Postdoctoral Fellow&lt;/b&gt; – National Research Council&lt;/div&gt;
    &lt;div style=&#34;text-align: right;&#34;&gt;Sept 2020 – July 2023&lt;/div&gt;
&lt;/div&gt;
&lt;ul style=&#34;margin-top: 0; padding: 0; margin-left: 40px;&#34;&gt;
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Tested quantum algorithm for differential equations on real IBM hardware&lt;/li&gt;	
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Numerical weather prediction using HPC&lt;/li&gt;		
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Received 2 publication awards from the U.S. Navy&lt;/li&gt;	
&lt;/ul&gt;
&lt;div style=&#34;display: flex; justify-content: space-between; margin-left: 20px;&#34;&gt;
    &lt;div style=&#34;text-align: left;&#34;&gt;&lt;b&gt;Graduate Student Researcher&lt;/b&gt; – UC San Diego&lt;/div&gt;
    &lt;div style=&#34;text-align: right;&#34;&gt;April 2014 – May 2020&lt;/div&gt;
&lt;/div&gt;
&lt;ul style=&#34;margin-top: 0; padding: 0; margin-left: 40px;&#34;&gt;	
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Dissertation – F. Martin Ralph: &lt;em&gt;Mesoscale Dynamics of Atmospheric Rivers&lt;/em&gt;&lt;/li&gt;		
    &lt;li style=&#34;margin-bottom: 1px;&#34;&gt;Mentored two undergraduate students on meteorological research projects&lt;/li&gt;	
&lt;/ul&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;h3 style=&#34;margin-bottom: 10px;&#34;&gt;
    &lt;span style=&#34;color:#3498db;&#34;&gt;Skills &lt;/span&gt;
&lt;/h3&gt;
&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;
	&lt;div style=&#34;text-align: left;margin-left: 20px;&#34;&gt;Programming&lt;/div&gt;
	&lt;div style=&#34;text-align: left; padding-left: 30px;&#34;&gt;Python | Fortran | Bash | NCL | LaTeX&lt;/div&gt;
&lt;/div&gt;
&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;
	&lt;div style=&#34;text-align: left;margin-left: 20px;&#34;&gt;Libraries&lt;/div&gt;
	&lt;div style=&#34;text-align: left; padding-left: 73px;&#34;&gt;Qiskit | SciPy | NumPy | pandas | Matplotlib | multiprocessing | Xarray &lt;/div&gt;
&lt;/div&gt;
&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;
	&lt;div style=&#34;text-align: left;margin-left: 20px;&#34;&gt;Computational&lt;/div&gt;
	&lt;div style=&#34;text-align: left; padding-left: 21px;&#34;&gt;Linux | High-Performance Computing | Parallel Processing | MPI &lt;/div&gt;
&lt;/div&gt;
&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;
	&lt;div style=&#34;text-align: left;margin-left: 20px;&#34;&gt;Math Tools&lt;/div&gt;
	&lt;div style=&#34;text-align: left; padding-left: 52px;&#34;&gt;Variational Algorithms | Matrix Decompositions | Circuit Design&lt;/div&gt;	
&lt;/div&gt;
&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;
	&lt;div style=&#34;text-align: left; padding-left: 161px;&#34;&gt;Optimization | Solutions of Differential Equations | Lattice Boltzmann&lt;/div&gt;	
&lt;/div&gt;
&lt;div style=&#34;display: flex; align-items: center;&#34;&gt;
	&lt;div style=&#34;text-align: left; padding-left: 161px;&#34;&gt;Ansatz Design | Carleman Linearization | Quantum Data Loading&lt;/div&gt;	
&lt;/div&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;h3 style=&#34;margin-bottom: 10px;&#34;&gt;
    &lt;span style=&#34;color:#3498db;&#34;&gt;Publications &lt;/span&gt;
&lt;/h3&gt;
&lt;h4 style=&#34;margin-bottom: 10px; margin-top: 0px; margin-left: 20px; color:#3498db;&#34;&gt;
    &lt;span&gt;&lt;u&gt;Quantum Computing&lt;/u&gt;&lt;/span&gt;
&lt;/h4&gt;
&lt;ul style=&#34;margin-top: 0; padding: 0; margin-left: 40px;&#34;&gt;
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2025). &lt;b&gt;An Efficient Decomposition of the Carleman Linearized Burgers’ Equation&lt;/b&gt;. Quantum (&lt;em&gt;in rev&lt;/em&gt;). &lt;a href=&#34;https://doi.org/10.48550/arXiv.2505.00285&#34;&gt;https://doi.org/10.48550/arXiv.2505.00285&lt;/a&gt;&lt;/li&gt;
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2022). &lt;b&gt;Variational Quantum Solutions to the Advection–Diffusion Equation for Applications in Fluid Dynamics&lt;/b&gt;. Quantum Inf Process. &lt;a href=&#34;https://doi.org/10.1007/s11128-022-03667-7&#34;&gt;https://doi.org/10.1007/s11128-022-03667-7&lt;/a&gt;&lt;/li&gt;	
&lt;/ul&gt;
&lt;h4 style=&#34;margin-bottom: 10px; margin-top: 0px; margin-left: 20px; color:#3498db;&#34;&gt;
    &lt;span&gt;&lt;u&gt;Weather and Fluid Dynamics&lt;/u&gt;&lt;/span&gt;
&lt;/h4&gt;	
&lt;ul style=&#34;margin-top: 0; padding: 0; margin-left: 40px;&#34;&gt;	
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2023). &lt;b&gt;Preconditioning and Intensification of Upstream Extratropical Cyclones through Surface Fluxes&lt;/b&gt;. JAS. &lt;a href=&#34;https://doi.org/10.1175/JAS-D-22-0251.1&#34;&gt;https://doi.org/10.1175/JAS-D-22-0251.1&lt;/a&gt;&lt;/li&gt;
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2022). &lt;b&gt;On the Influence of Surface Latent Heat Fluxes on Idealized Extratropical Cyclones&lt;/b&gt;. JAS. &lt;a href=&#34;https://doi.org/10.1175/JAS-D-22-0035.1&#34;&gt;https://doi.org/10.1175/JAS-D-22-0035.1&lt;/a&gt;&lt;/li&gt;		
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2021). &lt;b&gt;The Circulation Response of a Two-Dimensional Frontogenetic Model to Optimized Moisture Perturbations&lt;/b&gt;. JAS. &lt;a href=&#34;https://doi.org/10.1175/JAS-D-20-0102.1&#34;&gt;https://doi.org/10.1175/JAS-D-20-0102.1&lt;/a&gt;&lt;/li&gt;
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2020). &lt;b&gt;Dropsonde Observations of the Ageostrophy within the Pre-Cold-Frontal Low-Level Jet Associated with Atmospheric Rivers&lt;/b&gt;. MWR. &lt;a href=&#34;https://doi.org/10.1175/MWR-D-19-0248.1&#34;&gt;https://doi.org/10.1175/MWR-D-19-0248.1&lt;/a&gt;&lt;/li&gt;
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Demirdjian et al. (2020). &lt;b&gt;A Case Study of the Physical Processes Associated with the Atmospheric River Initial-Condition Sensitivity from an Adjoint Model&lt;/b&gt;. JAS. &lt;a href=&#34;https://doi.org/10.1175/JAS-D-19-0155.1&#34;&gt;https://doi.org/10.1175/JAS-D-19-0155.1&lt;/a&gt;&lt;/li&gt;	
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Norris et al. (2020). &lt;b&gt;The Observed Water Vapor Budget in an Atmospheric River over the Northeast Pacific&lt;/b&gt;. J.Hydro. &lt;a href=&#34;https://doi.org/10.1175/JHM-D-20-0048.1&#34;&gt;https://doi.org/10.1175/JHM-D-20-0048.1&lt;/a&gt;&lt;/li&gt;	
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Cannon et al. (2020). &lt;b&gt;TGPM Satellite Radar Observations of Precipitation Mechanisms in Atmospheric Rivers&lt;/b&gt;. MWR. &lt;a href=&#34;https://doi.org/10.1175/MWR-D-19-0278.1&#34;&gt;https://doi.org/10.1175/MWR-D-19-0278.1&lt;/a&gt;&lt;/li&gt;	
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Reynolds et al. (2019). &lt;b&gt;Adjoint Sensitivity of North Pacific Atmospheric River Forecasts&lt;/b&gt;. MWR. &lt;a href=&#34;https://doi.org/10.1175/MWR-D-18-0347.1&#34;&gt;https://doi.org/10.1175/MWR-D-18-0347.1&lt;/a&gt;&lt;/li&gt;  
    &lt;li style=&#34;margin-bottom: 10px;&#34;&gt;Martin et al. (2018). &lt;b&gt;Evaluation of Atmospheric River Predictions by the WRF Model Using Aircraft and Regional Mesonet Observations of Orographic Precipitation and Its Forcing&lt;/b&gt;. J.Hydro. &lt;a href=&#34;https://doi.org/10.1175/JHM-D-17-0098.1&#34;&gt;https://doi.org/10.1175/JHM-D-17-0098.1&lt;/a&gt;&lt;/li&gt;		
&lt;/ul&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;h3 style=&#34;margin-bottom: 10px;&#34;&gt;
    &lt;span style=&#34;color:#3498db;&#34;&gt;Presentations &lt;/span&gt;
&lt;/h3&gt;
&lt;ul style=&#34;margin-top: 0; padding: 0; margin-left: 40px;&#34;&gt;
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2024) Solutions of a Simple Nonlinear PDE using a Noisy Quantum Computer for Applications in Fluid Dynamics, Naval Surface Warfare Center, Carderock, Maryland. &lt;em&gt;&lt;b&gt;Invited&lt;/b&gt;&lt;/em&gt;
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2024) Solving Simple Nonlinear PDEs using Quantum Computers for Applications in Fluid Dynamics, AMS Annual. Baltimore, Maryland.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2024) Polar Low Genesis and Intensification Sensitivities to Oceanic Surface Fluxes Using an Idealized Model, Naval Quantum Working Group. &lt;em&gt;&lt;b&gt;Invited&lt;/b&gt;&lt;/em&gt;	
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2023) Modeling and Forecasting Panel. Quantum For Climate &amp; Sustainability, General Electric, Niskayuna, NY. &lt;em&gt;&lt;b&gt;Invited&lt;/b&gt;&lt;/em&gt;	
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2022) Quantum Computing Applications relevant for Numerical Weather Prediction. Zapata Seminar. &lt;em&gt;&lt;b&gt;Invited&lt;/b&gt;&lt;/em&gt;	
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2022) Surface Latent Heat Flux Influence on Idealized Extratropical Cyclones. International Atmospheric Rivers Conference 2022, Santiago, Chile.		
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2022) On the Influence of Surface Latent Heat Fluxes on Idealized Extratropical Cyclones. 3rd Pan-GASS Meeting Understanding and Modeling Atmospheric Processes, Monterey, CA.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2022) Quantum Computing and Numerical Weather Prediction. AMS Annual 2022, Houston, TX.	
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2022) Latent Heat Flux Influence on Idealized Extratropical Cyclones, Atmospheric Rivers and the Conveyor Belt Model. AMS Annual 2022, Houston, TX.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2020) A Case Study of the Physical Processes Associated with the Atmospheric River Initial Condition Sensitivity from an Adjoint Model. AMS Annual, Boston, MA.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2019) A Case Study of the Physical Processes Associated with the Atmospheric River Initial Condition Sensitivity from an Adjoint Model. 18th Conference on Mesoscale Processes, Savannah, GA.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2018) An Airborne and Surface-Based Study of the Complete Water Vapor Budget and Associated Dynamical Processes in an Atmospheric River over the Northeast Pacific. Naval Research Laboratory Seminar, Monterey, CA. &lt;em&gt;&lt;b&gt;Invited&lt;/b&gt;&lt;/em&gt;
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2018) On the use of a height tendency analysis for physical process studies. International Atmospheric Rivers Conference 2018. La Jolla, CA, Scripps Institution of Oceanography.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2018) Diagnostics of the Ageostrophic Component of a Pre-Frontal Low-Level Jet Using the WRF Model. 18th Conference on Mesoscale Processes: San Diego, CA.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2017) Dropsonde Observations of the Ageostrophy of the Pre-Cold-Frontal Low-Level Jet in Atmospheric Rivers, and its Role in Modulating Water Vapor Transport. 18th Cyclone Workshop: Sainte Adele, Quebec, Canada, U. Albany.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2017) A Theory for the Forcing Mechanism of the Ageostrophic Component of the Pre-Frontal Low-Level Jet. AMS Annual 2017, Seattle, WA.
	&lt;li style=&#34;margin-bottom: 10px;&#34;&gt;(2015) Skill Test of the West-WRF and GFS Models Verified Using CalWater Dropsonde Observations. AGU Fall Meeting 2015, San Francisco, CA, Amer. Geophys. Union.
&lt;/li&gt;
&lt;/ul&gt;</description>
      <content:encoded><![CDATA[<div class="container" style="display: flex; align-items: flex-start;">
    <div class="text" style="flex: 1; padding-right: 20px;">
		<h2 style="margin-bottom: 10px;">
			<span style="color:#3498db;">Reuben Demirdjian</span>
		</h2>
		<div style="display: flex; justify-content: space-between; margin-left: 20px;">
			<div style="text-align: left;"><b>Contact</b>: ReubenDemi at gmail dot com</div>
		</div>
		<div style="display: flex; justify-content: space-between; margin-left: 20px;">
			<div style="text-align: left;"><a href="https://scholar.google.com/citations?user=jUAkP-kAAAAJ&hl=en">Google Scholar</a></div>
		</div>
		<div style="display: flex; justify-content: space-between; margin-left: 20px;">
			<div style="text-align: left;"><a href="https://www.linkedin.com/in/reuben-demirdjian/">LinkedIn</a></div>
		</div>
    </div>
    <img src="Headshot_circle.png" style="max-width: 25%; height: auto; margin-top: 30px; margin-right: 30px;">
</div>
<br>
<hr>
<h3 style="margin-bottom: 10px;">
    <span style="color:#3498db;">Education</span>
</h3>
<div style="display: flex; justify-content: space-between; margin-left: 20px;">
    <div style="text-align: left;"><b>PhD in Oceanography</b>, University of California, San Diego</div>
    <div style="text-align: right;">Sept 2014 – May 2020</div>
</div>
<div style="display: flex; justify-content: space-between; margin-left: 20px;">
    <div style="text-align: left;"><b>Bsc in Mathematics</b>, University of California, Santa Barbara</div>
    <div style="text-align: right;">Sept 2010 – June 2012</div>
</div>
<div style="display: flex; justify-content: space-between; margin-left: 20px;">
    <div style="text-align: left;"><b>Bsc in Physics</b>, University of California, Santa Barbara</div>
    <div style="text-align: right;">Sept 2010 – June 2012</div>
</div>
<br>
<hr>
<h3 style="margin-bottom: 10px;">
    <span style="color:#3498db;">Work Experience</span>
</h3>
<div style="display: flex; justify-content: space-between; margin-left: 20px;">
    <div style="text-align: left;"><b>Research Meteorologist</b> – U.S. Naval Research Laboratory</div>
    <div style="text-align: right;">July 2023 – Present</div>
</div>
<ul style="margin-top: 0; padding: 0; margin-left: 40px;">
    <li style="margin-bottom: 1px;">Develop and optimize quantum algorithms to solve differential equations</li>
    <li style="margin-bottom: 1px;">Supervise a postdoc developing algorithms with end-to-end resource analysis</li>
    <li style="margin-bottom: 1px;">Weather model development for high-performance computers</li>
	<li style="margin-bottom: 1px;">Dynamical and statistical analysis of weather model data</li>
</ul>
<div style="display: flex; justify-content: space-between; margin-left: 20px;">
    <div style="text-align: left;"><b>Postdoctoral Fellow</b> – National Research Council</div>
    <div style="text-align: right;">Sept 2020 – July 2023</div>
</div>
<ul style="margin-top: 0; padding: 0; margin-left: 40px;">
    <li style="margin-bottom: 1px;">Tested quantum algorithm for differential equations on real IBM hardware</li>	
    <li style="margin-bottom: 1px;">Numerical weather prediction using HPC</li>		
    <li style="margin-bottom: 1px;">Received 2 publication awards from the U.S. Navy</li>	
</ul>
<div style="display: flex; justify-content: space-between; margin-left: 20px;">
    <div style="text-align: left;"><b>Graduate Student Researcher</b> – UC San Diego</div>
    <div style="text-align: right;">April 2014 – May 2020</div>
</div>
<ul style="margin-top: 0; padding: 0; margin-left: 40px;">	
    <li style="margin-bottom: 1px;">Dissertation – F. Martin Ralph: <em>Mesoscale Dynamics of Atmospheric Rivers</em></li>		
    <li style="margin-bottom: 1px;">Mentored two undergraduate students on meteorological research projects</li>	
</ul>
<br>
<hr>
<h3 style="margin-bottom: 10px;">
    <span style="color:#3498db;">Skills </span>
</h3>
<div style="display: flex; align-items: center;">
	<div style="text-align: left;margin-left: 20px;">Programming</div>
	<div style="text-align: left; padding-left: 30px;">Python | Fortran | Bash | NCL | LaTeX</div>
</div>
<div style="display: flex; align-items: center;">
	<div style="text-align: left;margin-left: 20px;">Libraries</div>
	<div style="text-align: left; padding-left: 73px;">Qiskit | SciPy | NumPy | pandas | Matplotlib | multiprocessing | Xarray </div>
</div>
<div style="display: flex; align-items: center;">
	<div style="text-align: left;margin-left: 20px;">Computational</div>
	<div style="text-align: left; padding-left: 21px;">Linux | High-Performance Computing | Parallel Processing | MPI </div>
</div>
<div style="display: flex; align-items: center;">
	<div style="text-align: left;margin-left: 20px;">Math Tools</div>
	<div style="text-align: left; padding-left: 52px;">Variational Algorithms | Matrix Decompositions | Circuit Design</div>	
</div>
<div style="display: flex; align-items: center;">
	<div style="text-align: left; padding-left: 161px;">Optimization | Solutions of Differential Equations | Lattice Boltzmann</div>	
</div>
<div style="display: flex; align-items: center;">
	<div style="text-align: left; padding-left: 161px;">Ansatz Design | Carleman Linearization | Quantum Data Loading</div>	
</div>
<br>
<hr>
<h3 style="margin-bottom: 10px;">
    <span style="color:#3498db;">Publications </span>
</h3>
<h4 style="margin-bottom: 10px; margin-top: 0px; margin-left: 20px; color:#3498db;">
    <span><u>Quantum Computing</u></span>
</h4>
<ul style="margin-top: 0; padding: 0; margin-left: 40px;">
    <li style="margin-bottom: 10px;">Demirdjian et al. (2025). <b>An Efficient Decomposition of the Carleman Linearized Burgers’ Equation</b>. Quantum (<em>in rev</em>). <a href="https://doi.org/10.48550/arXiv.2505.00285">https://doi.org/10.48550/arXiv.2505.00285</a></li>
    <li style="margin-bottom: 10px;">Demirdjian et al. (2022). <b>Variational Quantum Solutions to the Advection–Diffusion Equation for Applications in Fluid Dynamics</b>. Quantum Inf Process. <a href="https://doi.org/10.1007/s11128-022-03667-7">https://doi.org/10.1007/s11128-022-03667-7</a></li>	
</ul>
<h4 style="margin-bottom: 10px; margin-top: 0px; margin-left: 20px; color:#3498db;">
    <span><u>Weather and Fluid Dynamics</u></span>
</h4>	
<ul style="margin-top: 0; padding: 0; margin-left: 40px;">	
    <li style="margin-bottom: 10px;">Demirdjian et al. (2023). <b>Preconditioning and Intensification of Upstream Extratropical Cyclones through Surface Fluxes</b>. JAS. <a href="https://doi.org/10.1175/JAS-D-22-0251.1">https://doi.org/10.1175/JAS-D-22-0251.1</a></li>
    <li style="margin-bottom: 10px;">Demirdjian et al. (2022). <b>On the Influence of Surface Latent Heat Fluxes on Idealized Extratropical Cyclones</b>. JAS. <a href="https://doi.org/10.1175/JAS-D-22-0035.1">https://doi.org/10.1175/JAS-D-22-0035.1</a></li>		
    <li style="margin-bottom: 10px;">Demirdjian et al. (2021). <b>The Circulation Response of a Two-Dimensional Frontogenetic Model to Optimized Moisture Perturbations</b>. JAS. <a href="https://doi.org/10.1175/JAS-D-20-0102.1">https://doi.org/10.1175/JAS-D-20-0102.1</a></li>
    <li style="margin-bottom: 10px;">Demirdjian et al. (2020). <b>Dropsonde Observations of the Ageostrophy within the Pre-Cold-Frontal Low-Level Jet Associated with Atmospheric Rivers</b>. MWR. <a href="https://doi.org/10.1175/MWR-D-19-0248.1">https://doi.org/10.1175/MWR-D-19-0248.1</a></li>
    <li style="margin-bottom: 10px;">Demirdjian et al. (2020). <b>A Case Study of the Physical Processes Associated with the Atmospheric River Initial-Condition Sensitivity from an Adjoint Model</b>. JAS. <a href="https://doi.org/10.1175/JAS-D-19-0155.1">https://doi.org/10.1175/JAS-D-19-0155.1</a></li>	
    <li style="margin-bottom: 10px;">Norris et al. (2020). <b>The Observed Water Vapor Budget in an Atmospheric River over the Northeast Pacific</b>. J.Hydro. <a href="https://doi.org/10.1175/JHM-D-20-0048.1">https://doi.org/10.1175/JHM-D-20-0048.1</a></li>	
    <li style="margin-bottom: 10px;">Cannon et al. (2020). <b>TGPM Satellite Radar Observations of Precipitation Mechanisms in Atmospheric Rivers</b>. MWR. <a href="https://doi.org/10.1175/MWR-D-19-0278.1">https://doi.org/10.1175/MWR-D-19-0278.1</a></li>	
    <li style="margin-bottom: 10px;">Reynolds et al. (2019). <b>Adjoint Sensitivity of North Pacific Atmospheric River Forecasts</b>. MWR. <a href="https://doi.org/10.1175/MWR-D-18-0347.1">https://doi.org/10.1175/MWR-D-18-0347.1</a></li>  
    <li style="margin-bottom: 10px;">Martin et al. (2018). <b>Evaluation of Atmospheric River Predictions by the WRF Model Using Aircraft and Regional Mesonet Observations of Orographic Precipitation and Its Forcing</b>. J.Hydro. <a href="https://doi.org/10.1175/JHM-D-17-0098.1">https://doi.org/10.1175/JHM-D-17-0098.1</a></li>		
</ul>
<br>
<hr>
<h3 style="margin-bottom: 10px;">
    <span style="color:#3498db;">Presentations </span>
</h3>
<ul style="margin-top: 0; padding: 0; margin-left: 40px;">
	<li style="margin-bottom: 10px;">(2024) Solutions of a Simple Nonlinear PDE using a Noisy Quantum Computer for Applications in Fluid Dynamics, Naval Surface Warfare Center, Carderock, Maryland. <em><b>Invited</b></em>
	<li style="margin-bottom: 10px;">(2024) Solving Simple Nonlinear PDEs using Quantum Computers for Applications in Fluid Dynamics, AMS Annual. Baltimore, Maryland.
	<li style="margin-bottom: 10px;">(2024) Polar Low Genesis and Intensification Sensitivities to Oceanic Surface Fluxes Using an Idealized Model, Naval Quantum Working Group. <em><b>Invited</b></em>	
	<li style="margin-bottom: 10px;">(2023) Modeling and Forecasting Panel. Quantum For Climate & Sustainability, General Electric, Niskayuna, NY. <em><b>Invited</b></em>	
	<li style="margin-bottom: 10px;">(2022) Quantum Computing Applications relevant for Numerical Weather Prediction. Zapata Seminar. <em><b>Invited</b></em>	
	<li style="margin-bottom: 10px;">(2022) Surface Latent Heat Flux Influence on Idealized Extratropical Cyclones. International Atmospheric Rivers Conference 2022, Santiago, Chile.		
	<li style="margin-bottom: 10px;">(2022) On the Influence of Surface Latent Heat Fluxes on Idealized Extratropical Cyclones. 3rd Pan-GASS Meeting Understanding and Modeling Atmospheric Processes, Monterey, CA.
	<li style="margin-bottom: 10px;">(2022) Quantum Computing and Numerical Weather Prediction. AMS Annual 2022, Houston, TX.	
	<li style="margin-bottom: 10px;">(2022) Latent Heat Flux Influence on Idealized Extratropical Cyclones, Atmospheric Rivers and the Conveyor Belt Model. AMS Annual 2022, Houston, TX.
	<li style="margin-bottom: 10px;">(2020) A Case Study of the Physical Processes Associated with the Atmospheric River Initial Condition Sensitivity from an Adjoint Model. AMS Annual, Boston, MA.
	<li style="margin-bottom: 10px;">(2019) A Case Study of the Physical Processes Associated with the Atmospheric River Initial Condition Sensitivity from an Adjoint Model. 18th Conference on Mesoscale Processes, Savannah, GA.
	<li style="margin-bottom: 10px;">(2018) An Airborne and Surface-Based Study of the Complete Water Vapor Budget and Associated Dynamical Processes in an Atmospheric River over the Northeast Pacific. Naval Research Laboratory Seminar, Monterey, CA. <em><b>Invited</b></em>
	<li style="margin-bottom: 10px;">(2018) On the use of a height tendency analysis for physical process studies. International Atmospheric Rivers Conference 2018. La Jolla, CA, Scripps Institution of Oceanography.
	<li style="margin-bottom: 10px;">(2018) Diagnostics of the Ageostrophic Component of a Pre-Frontal Low-Level Jet Using the WRF Model. 18th Conference on Mesoscale Processes: San Diego, CA.
	<li style="margin-bottom: 10px;">(2017) Dropsonde Observations of the Ageostrophy of the Pre-Cold-Frontal Low-Level Jet in Atmospheric Rivers, and its Role in Modulating Water Vapor Transport. 18th Cyclone Workshop: Sainte Adele, Quebec, Canada, U. Albany.
	<li style="margin-bottom: 10px;">(2017) A Theory for the Forcing Mechanism of the Ageostrophic Component of the Pre-Frontal Low-Level Jet. AMS Annual 2017, Seattle, WA.
	<li style="margin-bottom: 10px;">(2015) Skill Test of the West-WRF and GFS Models Verified Using CalWater Dropsonde Observations. AGU Fall Meeting 2015, San Francisco, CA, Amer. Geophys. Union.
</li>
</ul>]]></content:encoded>
    </item>
    <item>
      <title>Data Loading on a Quantum Computer: Part 2</title>
      <link>http://localhost:1313/website/data_loading_part2/</link>
      <pubDate>Wed, 30 Apr 2025 00:00:00 +0000</pubDate><author>ReubenDemi@gmail.com (Reuben Demirdjian)</author>
      <guid>http://localhost:1313/website/data_loading_part2/</guid>
      <description>&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [[&#39;$&#39;,&#39;$&#39;]],
    displayMath: [[&#39;$$&#39;,&#39;$$&#39;]],
    processEscapes: true,
    processEnvironments: true,
    skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;],
    TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; },
         extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] }
  }
});
&lt;/script&gt;
&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
  MathJax.Hub.Queue(function() {
    // Fix &lt;code&gt; tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
    }
});
&lt;/script&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;This post is part 2 of a series where I discuss data loading for solving linear systems of equations. Our method extends the approach pioneerd by &lt;a href=&#34;#1&#34;&gt;Gnanasekaran and Surana (2024)&lt;/a&gt;, which I discussed in &lt;a href=&#34;https://reubendemirdjian.github.io/data_loading_part1/&#34;&gt;Part 1&lt;/a&gt;. I highly recommend that you first read Part 1, otherwise this post may not make much sense.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<h3 id="introduction">Introduction</h3>
<p>This post is part 2 of a series where I discuss data loading for solving linear systems of equations. Our method extends the approach pioneerd by <a href="#1">Gnanasekaran and Surana (2024)</a>, which I discussed in <a href="https://reubendemirdjian.github.io/data_loading_part1/">Part 1</a>. I highly recommend that you first read Part 1, otherwise this post may not make much sense.</p>
<p>Here, I&rsquo;ll break down the methods used in my <a href="#2">recent article</a> where we <em>solved</em> the data loading problem for the 1D Burgers&rsquo; equation - a paradigmatic nonlinear partial differential equation (PDE) relevant for fluid dynamics. Here I put solved in italics because our method applies specifically to the <a href="#3">VQLS</a> algorithm, which utilizes the linear combination of unitaries (LCU) theorem. It is possible that our mehtod also applies to other quantum linear system algorithms that utilize LCU, but that remains to be seen and is the subject of future work.</p>
<p>The goal of this writeup is as follows. Consider some (huge) matrix $\mathcal{A}\in\mathbb{R}^{N\times N}$, then we want to find
$$
\begin{equation}
\mathcal{A} = \sum_{l=1}^{N_s} c_l\mathcal{A}_l
\end{equation}
$$
where $c_l\in\mathbb{C}$ and $\mathcal{A}_l\in\mathbb{R}^{N\times N}$ are specific types of <u>nonunitary</u> matrices. These $\mathcal{A}_l$ are specially defined to be block encoded within unitary matrices that have efficient circuit implementations for VQLS. A key part of this method is that $N_s$ be a polylogarithmic (polylog) function of $N$, otherwise any quantum advantage is lost to data loading.</p>
<p>You might be wondering, isn&rsquo;t it simpler to find a decomposition such that the $\mathcal{A}_l$ matrices are themselves unitary thereby saving ourselves from the block encoding step? The answer is yes, that is the ideal approach. However, there are instances when this sort of decomposition is not possible with an $N_s$ that is polylog. In those instances, our block encoding method is simply an alternative for data loading and requires only a single qubit more of overhead.</p>
<h3 id="transforming-from-nonlinear-to-linear">Transforming from Nonlinear to Linear</h3>
<p>Before we discuss data loading, we first need to setup the problem. Consider the generic second order nonlinear ordinary differential equation (ODE)</p>
<p>$$\begin{equation}\tag{1}\label{eqn:IVP}
\frac{\partial \vec{f}}{\partial t} = F_1 \vec{f} + F_2\vec{f}^{\otimes 2}
\end{equation}$$</p>
<p>where $\vec{f}(t) = \bigl( f_1(t),\dots,f_N(t) \bigr)^T\in\mathbb{R}^N$ and $F_k\in\mathbb{R}^{N\times N^k}$ for $k\in\{1,2\}$. The Burgers&rsquo; equation can be written in the above form, but for now we will work with the generalized form.</p>
<p>Next, we implement the following on eq. \eqref{eqn:IVP}:</p>
<ol>
<li>Carleman linearization from <a href="#4">Liu et al. (2021)</a> &ndash; transforms our finite nonlinear ODE into an infinite linear ODE,</li>
<li>Truncation of the infinite ODE to order $\alpha$ &ndash; forms a finite linear ODE,</li>
<li>Temporal discretization using backward Euler with $n_t$ time steps of size $\Delta t$ &ndash; transforms the finite linear ODE into a finite linear system of equations.</li>
</ol>
<p>These methods transform eq. \eqref{eqn:IVP} into a linear system of equations of the form $L\vec{Y}=\vec{B} $ where $L\in\mathbb{C}^{n_t\Delta\times n_t\Delta}$, $\Delta=\sum_{j=1}^\alpha N^j$, and $\vec{Y},\vec{B}\in\mathbb{C}^{n_t\Delta}$. A solution to this linear system provides an <u>approximate solution</u> to our original nonlinear ODE. Note that, while the accuracy of the problem improves with increasing $\alpha$, the size of the linear system unfortunately scales exponentially with $\alpha$. This tension means that choosing the appropriate $\alpha$ is critical.</p>
<p>So, what is this matrix $L$ and how does it relate to eq. \eqref{eqn:IVP}? Let&rsquo;s pick it apart piece by piece to see. By definition
$$L = \begin{pmatrix} \tag{2} \label{eqn:L}
I  &amp; 0 &amp; \dots &amp; 0 \\
-I &amp; I-\Delta t A &amp; \dots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \vdots \\
0  &amp; \dots &amp; -I &amp; I-\Delta t A
\end{pmatrix},
$$
where each block in $L$ evolves the system forward by $\Delta t$ with $n_t$ total blocks. To continue to pick $L$ apart, we break open the $A$ matrices defined by
$$
\begin{equation} \tag{3} \label{eqn:A}
A = \begin{pmatrix}
A_1^1 &amp; A_2^1 &amp; 0 &amp; &hellip; &amp; 0 \\
0 &amp; A_2^2 &amp; A_3^2 &amp; &hellip;  &amp; 0 \\
\vdots &amp; \dots &amp; \ddots &amp; \ddots &amp; \ddots \\
0 &amp; \dots &amp; \dots &amp; A_{\alpha-1}^{\alpha-1} &amp; A_\alpha^{\alpha-1} \\
0 &amp; \dots &amp; \dots &amp; 0 &amp; A_\alpha^\alpha
\end{pmatrix}
\end{equation}
$$
where we can see that the size of $A$ depends upon the truncation order $\alpha$. By inspection of $A$, we identify two types of block matrices: $A_j^j$ and $A_{j+1}^j$ defined by
$$
\begin{equation}
A_j^j = \sum_{l=0}^{j-1} I_{n_x}^{\otimes l} \otimes F_1 \otimes I_{n_x}^{\otimes j-l-1}, \quad
A_{j+1}^j = \sum_{l=0}^{j-1} I_{n_x}^{\otimes l} \otimes F_2 \otimes I_{n_x}^{\otimes j-l-1} .
\end{equation}
$$
You can think of the $A_j^j$ and $A_{j+1}^j$ blocks as implementing the dynamics contained in the $F_1$ and $F_2$ matrices respectively. The example below should help you get a better feeling for the structure of this kind of matrix.</p>
<div style="border-radius: 10px; background: beige; padding: 10px; color: black">
	<h4 style="margin:0.3em 0"><u>Example 1</u></h4> 
	Consider the 1D spatially discretized Burgers' equation
	$$\begin{equation} 
		\frac{\partial u_j}{\partial t} = \underbrace{\frac{\nu}{\Delta x^2}(u_{j+1} - 2u_j + u_{j-1})}_{F_1\vec{u}} - \underbrace{\frac{u_j}{2\Delta x}(u_{j+1}-u_{j-1})}_{F_2\vec{u}^{\otimes 2}}
	\end{equation} $$
	where $u_j(t)=(u_1(t),\dots,u_{n_x}(t))^T$, $\nu$ is the diffusion coefficient, and $\Delta x$ is the grid spacing. This can be rewriten into the form of eq. \eqref{eqn:IVP} where the $F_1$ and $F_2$ terms are shown in the underbraces. 
	<br><br>
	Let's consider the example where $n_x=4$ and $\alpha=2$. The $A$ matrix defined from eq. \eqref{eqn:A} takes the form in the figure below.
	<p class="aligncenter">
		<img src="Matrix_A.png" alt="Matrix_A" /></p>
	<style>
	.aligncenter {
		text-align: center;
	}
	</style>
	The $A_j^j$ terms in this example are $A_1^1$ and $A_2^2$, which are square, sparse, highly structured matrices making data loading relatively straightforward. The only $A_{j+1}^j$ term in this example is $A_2^1$ which is a non-square, sparse, structured matrix making it much more difficult for data loading.
	<br><br>
	Now let's see how these matrices fit into the $L$ matrix from eq. \eqref{eqn:L} when $n_t=4$.
	<p class="aligncenter">
		<img src="Matrix_L.png" alt="Matrix_L" /></p>
	<style>
	.aligncenter {
		text-align: center;
	}
	</style>
	This is the full structure for the $L$ matrix where each block represents a time step (hence 4 blocks) and you can clearly see the repeating $A$ matrix structure along the main diagonal.
</div>
<p>So, now that we have gained some intuition about the structure of $L$, how would you go about decomposing it into a linear combination of unitaries with, importantly, a number of terms ($N_s$) that is polylog?</p>
<p>One of the challenges in doing this is that even though we know that $L$ is composed of these $A$ blocks, the differing sizes of the $A_j^j$ and $A_{j+1}^j$ terms makes it difficult to separate them out. But what if each $A_j^j$ and $A_{j+1}^j$ were the same size? Then, it becomes much easier to pick $A$, and thereby $L$, apart. This is exactly what I introduce in the next section.</p>
<h3 id="carleman-embedding">Carleman Embedding</h3>
<p>To circumvent the issue of each of the $A_j^j$ and $A_{j+1}^j$ blocks being differently sized, we&rsquo;ll use zero-padding to force their sizes to be equal. Define
$$
\begin{equation}
A_j^{(e),j} = \begin{pmatrix} A_j^j &amp; 0 \\ 0 &amp; 0 \end{pmatrix},
\quad
A_{j+1}^{(e),j} = \begin{pmatrix} A_{j+1}^j &amp; 0 \\ 0 &amp; 0 \end{pmatrix},
\end{equation}
$$
where the superscript $(e)$ stands for &ldquo;embed&rdquo; and the $0$ blocks are appropriately sized. Whereas $A_j^j$ and $A_{j+1}^j$ are sized $N^j \times N^j$ and $N^j \times N^{j+1}$ respectively, their embedded analogs $A_j^{(e),j}$ and $A_{j+1}^{(e),j}$ are sized $N^\alpha \times N^\alpha$ for all $j$. We then use these blocks to form a matrix analogous to \eqref{eqn:A} given by
$$
\begin{equation} \tag{4} \label{eqn:Ae}
A^{(e)} = \begin{pmatrix}
A_1^{(e),1} &amp; A_2^{(e),1} &amp; 0 &amp; &hellip; &amp; 0 \\
0 &amp; A_2^{(e),2} &amp; A_3^{(e),2} &amp; &hellip;  &amp; 0 \\
\vdots &amp; \dots &amp; \ddots &amp; \ddots &amp; \ddots \\
0 &amp; \dots &amp; \dots &amp; A_{\alpha-1}^{(e),\alpha-1} &amp; A_\alpha^{(e),\alpha-1} \\
0 &amp; \dots &amp; \dots &amp; 0 &amp; A_\alpha^{(e),\alpha}
\end{pmatrix} .
\end{equation}
$$</p>
<p>Given this new definition of $A^{(e)}$, we can then define an analogous linear system of equations of the form $L^{(e)} \vec{Y}^{(e)} = \vec{B}^{(e)}$ where
$$
L^{(e)} = \begin{pmatrix} \tag{5} \label{eqn:Le}
I  &amp; 0 &amp; \dots &amp; 0 \\
-I &amp; I-\Delta t A^{(e)} &amp; \dots &amp; 0 \\
\vdots &amp; \ddots &amp; \ddots &amp; \vdots \\
0  &amp; \dots &amp; -I &amp; I-\Delta t A^{(e)}
\end{pmatrix} .
$$
Even though this linear system is substantially larger than the previous version, we are using size as a resource enabling us to easily &ldquo;pick&rdquo; out each of the $A_j^j$ and $A_{j+1}^j$ blocks with limited overhead. This is demonstrated in the following example.</p>
<div style="border-radius: 10px; background: beige; padding: 10px; color: black">
	<h4 style="margin:0.3em 0"><u>Example 2</u></h4> 
	Consider again the setup from Example 1 with $n_x=4$, $n_t=4$, and $\alpha=2$. Then the structure of the $A^{(e)}$ matrix from eq. \eqref{eqn:Ae} looks a lot like the $A$ matrix, but with judicious zero-padding. 
	<p class="aligncenter">
		<img src="Matrix_Ae.png" alt="Matrix_Ae" /></p>
	<style>
	.aligncenter {
		text-align: center;
	}
	</style>
	Since each block is the same size, we can actually pick $A^{(e)}$ apart using the $\rho_j$ matrices defined in <a href="http://localhost:1313/website/data_loading_part1/">Part 1</a>. That is we have
	$$
	\begin{equation}
		A^{(e)} = \rho_0 \otimes A_1^{(e),1}
		  + \rho_1 \otimes A_2^{(e),1}
		  + \rho_3 \otimes A_2^{(e),2} .
	\end{equation}
	$$
	This simple decomposition is only possible because each of the $A_j^{(e),j}$ and $A_{j+1}^{(e),j}$ blocks are the same size. 
	<br><br>
	The decomposition of $L^{(e)}$ from eq. \eqref{eqn:Le} is also made easier since it is given by 
	$$
	\begin{equation}
		L^{(e)}
		=
		(\rho_4^{\otimes 2} - \rho_0\otimes\rho_0) \otimes A^{(e)}
		+ 
		(\rho_4^{\otimes 2} - \rho_4\otimes\rho_2 - \rho_2\otimes\rho_1)
		\otimes\rho_4^{\otimes 5}.
	\end{equation}
	$$
	<br>
	So, by inserting $A^{(e)}$ into $L^{(e)}$ we simply need to find decompositions for $A_1^{(e),1}$, $A_2^{(e),1}$, and $A_2^{(e),2}$, which is a  much easier problem than the original one of needing to find a decomposition for $L$ from eq. \eqref{eqn:L}. 
</div> 
<p>This demonstrates the key advantage of using this Carleman embedding (zero-padding) method. That being said, our job is not over since we must now decompose each of the $A_j^{(e),j}$ and $A_{j+1}^{(e),j}$ terms. But, importantly, we have reduced the problem from a daunting one to one that is more manageable. In Part 3 of this series, I will show how to fully decompose the matrix $L^{(e)}$ introduced here into explicit circuits to be run with the VQLS method.</p>
<p><strong>Questions or comments?</strong> ReubenDemi [at] gmail [dot] com</p>
<h2 id="references">References</h2>
<p><a id="1">[1]</a>
A. Gnanasekaran and A. Surana, &ldquo;Efficient Variational Quantum Linear Solver for Structured Sparse Matrices,&rdquo; 2024 IEEE International Conference on Quantum Computing and Engineering (QCE), Montreal, QC, Canada, 2024, pp. 199-210, <a href="https://arxiv.org/abs/2404.16991">doi: 10.1109/QCE60285.2024.00033</a></p>
<p><a id="2">[2]</a>
Demirdjian, Reuben, Thomas Hogancamp, and Daniel Gunlycke. &ldquo;An Efficient Decomposition of the Carleman Linearized Burgers&rsquo; Equation.&rdquo; arXiv preprint <a href="https://arxiv.org/abs/2505.00285">arXiv:2505.00285</a> (2025).</p>
<p><a id="3">[3]</a>
Bravo-Prieto, Carlos, et al. &ldquo;Variational quantum linear solver.&rdquo; Quantum 7 (2023): 1188.</p>
<p><a id="4">[4]</a>
Liu, Jin-Peng, et al. &ldquo;Efficient quantum algorithm for dissipative nonlinear differential equations.&rdquo; Proceedings of the National Academy of Sciences 118.35 (2021): e2026805118.</p>
]]></content:encoded>
    </item>
    <item>
      <title>Data Loading on a Quantum Computer: Part 1</title>
      <link>http://localhost:1313/website/data_loading_part1/</link>
      <pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><author>ReubenDemi@gmail.com (Reuben Demirdjian)</author>
      <guid>http://localhost:1313/website/data_loading_part1/</guid>
      <description>&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [[&#39;$&#39;,&#39;$&#39;]],
    displayMath: [[&#39;$$&#39;,&#39;$$&#39;]],
    processEscapes: true,
    processEnvironments: true,
    skipTags: [&#39;script&#39;, &#39;noscript&#39;, &#39;style&#39;, &#39;textarea&#39;, &#39;pre&#39;],
    TeX: { equationNumbers: { autoNumber: &#34;AMS&#34; },
         extensions: [&#34;AMSmath.js&#34;, &#34;AMSsymbols.js&#34;] }
  }
});
&lt;/script&gt;
&lt;script type=&#34;text/x-mathjax-config&#34;&gt;
  MathJax.Hub.Queue(function() {
    // Fix &lt;code&gt; tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i &lt; all.length; i += 1) {
        all[i].SourceElement().parentNode.className += &#39; has-jax&#39;;
    }
});
&lt;/script&gt;
&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;
&lt;p&gt;One of the bottlenecks for certain quantum algorithms is loading classical data
onto the quantum computer. Suppose you have developed an algorithm that
solves a particular problem exponentially faster than the best known classical methods,
if loading the data loading is slow, then all advantage is lost before the quantum algorithm does a single operation.&lt;/p&gt;</description>
      <content:encoded><![CDATA[<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    // Fix <code> tags after MathJax finishes running. This is a
    // hack to overcome a shortcoming of Markdown. Discussion at
    // https://github.com/mojombo/jekyll/issues/199
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>
<h3 id="introduction">Introduction</h3>
<p>One of the bottlenecks for certain quantum algorithms is loading classical data
onto the quantum computer. Suppose you have developed an algorithm that
solves a particular problem exponentially faster than the best known classical methods,
if loading the data loading is slow, then all advantage is lost before the quantum algorithm does a single operation.</p>
<p class="aligncenter">
	<img src="data_loading_gif_125.gif" alt="centered image" /></p>
<style>
.aligncenter {
	text-align: center;
	border-radius: 10px;
}
</style>	
<p>This is exactly the case for solving linear systems of equations. There are currently an array of quantum algorithms (<a href="#1">HHL</a>, <a href="#2">CKS</a>, <a href="#3">VQLS</a> etc.) out there that can solve<sup><a href="#4">4</a></sup> linear systems exponentially faster than any known classical algorithm. However, there is comparatively less work on the topic of efficiently loading the matrix $A$ (or $\vec{b}$) necessary to solve the system. My guess is that this is largely because data loading is an applications driven problem and, to date, quantum computers just aren&rsquo;t very useful for solving anything beyond sample problems.</p>
<p>Therefore, in a recent study of mine<sup><a href="#5">5</a></sup>, my collaborators and I decided to tackle the problem of data loading for the Burgers&rsquo; equation, a paradigmatic nonlinear partial differential equation (PDE) relevant in fluid dynamics. Ultimately, we are interested in more complicated PDEs, but this serves as a starting place.</p>
<p>You might be wondering, how do you use a quantum linear solver to solve the nonlinear Burgers&rsquo; equation? Without going into the weeds<sup><a href="#6">6</a></sup>, the nonlinear PDE is transformed into a (ludicrously large) linear system of the form $A\vec{x}=\vec{b}$. This enables us to circumvent the difficulty of solving nonliner equations with quantum computers.</p>
<p>Ultimately, a solution to this linear system will provide an approximate solution to the desired Burgers&rsquo; equation. Hence, we need an algorithm to load the classical matrix $A$ onto the quantum computer to then obtain a solution using one of the many quantum solvers. For this writeup, we will be relying on the VQLS method.</p>
<hr>
<h3 id="efficient-circuits-for-sparse-structured-matrices">Efficient Circuits for Sparse, Structured Matrices</h3>
<p>Before we can explain our contribution, we must first give an overview of the study that we built upon, that is, <a href="#7">Gnanasekaran and Surana (2024)</a>, henceforth called GS24. First, let&rsquo;s introduce a set that will be used extensively throughout this blog post.</p>
<p>$$\rho_0=\begin{pmatrix}1 &amp; 0 \\ 0 &amp; 0 \end{pmatrix},\quad \rho_1=\begin{pmatrix}0&amp;1\\0&amp;0\end{pmatrix},\quad \rho_2=\begin{pmatrix}0&amp;0\\1&amp;0\end{pmatrix},\\ \rho_3=\begin{pmatrix}0&amp;0\\0&amp;1\end{pmatrix},\quad \rho_4=\begin{pmatrix}1&amp;0\\0&amp;1\end{pmatrix}.$$</p>
<p>Next, suppose that we have some non-unitary matrix $A$ that we block encode as</p>
<p>$$U = \begin{pmatrix} A^c &amp; A \\ A &amp; A^c \end{pmatrix},$$</p>
<p>where the matrix $U$ is unitary and $A^c$ is called the orthogonal (or unitary) complement of $A$. Informally, you can think of $A^c$ as a non-unique matrix that makes $U$ unitary for some matrix $A$.</p>
<p>What GS24 showed is that if $A$ is block encoded into $U$ in this way, then it can be implemented into the <a href="#3">Variational Quantum Linear Solver</a> (VQLS) and a solution to the linear system can thereby be obtained. This is done by simply adding a single ancilla qubit, and I encourage you to look at their Section 2 and Figure 1 to see exactly how it is done.</p>
<p>So how do we construct a circuit for this block encoding? They found that that if $U$ is actually split into the product of two specific unitary matrices, then it becomes straightforward to find the appropriate circuit. The two unitaries are</p>
<p>$$U = U_1 U_2 := \begin{pmatrix} I-AA^T &amp; AA^T \\ AA^T &amp; I-AA^T \end{pmatrix}\begin{pmatrix} \bar{A} &amp; 0 \\ 0 &amp; \bar{A} \end{pmatrix}.$$</p>
<p>where $\bar{A}$ is called the unitary completion of $A$. To find the circuit, we must therefore determine how to find $\bar{A}$. Thankfully, this is exactly what Theorem 1 of GS24 tells us: <em>The unitary completion of $\rho_1$ and $\rho_2$ is $\sigma_x$, where $\sigma_x$ is the Pauli-X matrix. Similarly, the unitary completion of $\rho_0$, $\rho_3$, and $\rho_4$ is $\rho_4$.</em> Below is a simple example to illustrate this.</p>
<div style="border-radius: 10px; background: beige; padding: 10px; color: black">
	<h4 style="margin:0.3em 0"><u>Example 1</u></h4> 
	Suppose we have $A=\rho_1$, then by Theorem 1 of GS24, $\bar{A} = \sigma_x$. Therefore, 
	$$U_1 = \begin{pmatrix} \rho_3 & \rho_0 \\\ \rho_0 & \rho_3 \end{pmatrix} = \
	\begin{pmatrix} 0&0&1&0 \\\ 0&1&0&0 \\\ 1&0&0&0 \\\ 0&0&0&1 \end{pmatrix}$$
	$$U_2 = \begin{pmatrix} \sigma_x & 0 \\\ 0 & \sigma_x \end{pmatrix} =
	\begin{pmatrix} 0&1&0&0 \\\ 1&0&0&0 \\\ 0&0&0&1 \\\ 0&0&1&0  \end{pmatrix}$$ 
	The circuit for $U_1$ is an open CNOT gate, which is just a regular CNOT with $\sigma_x$ applied before and after the control. Next, since $U_2=I\otimes \sigma_x$, its circuit is a single $\sigma_x$ gate.  
	<br>
	The full circuit is given <a href="https://algassert.com/quirk#circuit={%22cols%22:[[%22H%22,%22H%22],[%22%E2%80%A2%22,1,%22X%22],[1,%22%E2%80%A2%22,1,%22X%22],[1,1,%22X%22],[1,1,%22X%22],[1,1,%22%E2%80%A2%22,%22X%22],[1,1,%22X%22]]}">here in Quirk</a> and reproduced below.  
	<br>
	<p class="aligncenter">
		<img src="Example1.png" alt="centered image" /></p>
	<style>
	.aligncenter {
		text-align: center;
	}
	</style>	
	Here we used the <a href="https://github.com/Strilanc/Quirk/wiki/How-to-use-Quirk#view-the-unitary-matrix-of-a-circuit-via-the-state-channel-duality">EPR pairs</a> trick, in which the state display shows the matrix of the operation. Note that the two Hadamard gates and first two CNOT gates are used to create the EPR pairs and have nothing to do with our block encoding. You can see that by applying the product $U_1U_2$ we obtain the appropriate block encoding for $\rho_1$ as desired. $\Box$
</div>
<p>I suggest trying the same for the other $\rho_j$, with $j\in\{0,2,3,4\}$ matrices and verifying that the resulting block encoded matrix $U$ is unitary for each of them.</p>
<p>To recap, so far we have learned how to create a circuit to block encoding the $\rho_j$ matrices for $j\in\{0,\dots,4\}$. This on its own isn&rsquo;t very interesting, but the innovation in the GS24 paper is how easy it is to scale up.</p>
<p>Informally, their Theorem 2 says: <em>if you have some matrix $A$ that is a tensor product of any combination of the $\rho_j$ terms, then $\bar{A}$ is simply the tensor product of the individual unitary completions.</em> The example below illustrates this point.</p>
<div style="border-radius: 10px; background: beige; padding: 10px; color: black">
	<h4 style="margin:0.3em 0"><u>Example 2</u></h4>
	$$A = \rho_0 \otimes \rho_1 \otimes \rho_2 \implies \bar{A} = \rho_4 \otimes \sigma_x \otimes \sigma_x.$$ Therefore,
	$$ U_1 = \begin{pmatrix} I-\rho_{003} & \rho_{003} \\\ \rho_{003} & I-\rho_{003} \end{pmatrix}, \quad U_2 = \begin{pmatrix} \rho_4\otimes\sigma_x\otimes\sigma_x & 0 \\\ 0 & \rho_4\otimes\sigma_x\otimes\sigma_x \end{pmatrix},$$
	where I have used the notation $\rho_{ijk}=\rho_i\otimes\rho_j\otimes\rho_k$. As before, the $U_1$ circuit is constructed by a single control NOT gate, but this time there are multiple controls. Similarly, since $U_2$ has two $\sigma_x$ components, it is comprised of just two $\sigma_x$ gates. The full circuit is given <a href="https://algassert.com/quirk#circuit={%22cols%22:[[%22H%22,%22H%22,%22H%22,%22H%22],[%22%E2%80%A2%22,1,1,1,%22X%22],[1,%22%E2%80%A2%22,1,1,1,%22X%22],[1,1,%22%E2%80%A2%22,1,1,1,%22X%22],[1,1,1,%22%E2%80%A2%22,1,1,1,%22X%22],[1,1,1,1,%22X%22,%22X%22],[1,1,1,1,1,%22X%22,%22X%22],[1,1,1,1,%22%E2%80%A2%22,%22%E2%80%A2%22,%22%E2%80%A2%22,%22X%22],[1,1,1,1,1,%22X%22,%22X%22]]}">here in Quirk</a> and reproduced below.  
	<br>
	<p class="aligncenter">
		<img src="Example2.png" alt="centered image" /></p>
	<style>
	.aligncenter {
		text-align: center;
	}
	</style>	
	By applying the product $U_1U_2$ we obtain the appropriate block encoding for $\rho_{012}$ as desired. $\Box$
</div>
<p>You may be wondering, how did you determine which controls to apply (open vs. closed) for the $U_1$ gate in Example 2? This comes directly from the proof of Theorem 3 in GS24 where they provide an algorithm for exactly this purpose, summarized as follows: <em>For each component of the matrix $A$, take the product with its transpose. If $\rho_j\rho_j^T = \rho_0$ then apply an open control, if $\rho_j\rho_j^T = \rho_3$ apply a closed control, and if $\rho_j\rho_j^T = \rho_4$ apply no control.</em></p>
<p>For Example 2 we have, $A=\rho_{012}$ so for each component we have $\rho_0\rho_0^T=\rho_0$, $\rho_1\rho_1^T=\rho_0$, and $\rho_2\rho_2^T=\rho_3$, which results in an open control, open control, and closed control respectively.</p>
<p>Next, let&rsquo;s go arbitrarily large.</p>
<div style="border-radius: 10px; background: beige; padding: 10px; color: black">
	<h4 style="margin:0.3em 0"><u>Example 3</u></h4>
	$$A=\rho_{01234\dots 01234} \implies$$ $$\bar{A}=\rho_4\otimes\sigma_x\otimes\sigma_x\otimes\rho_4\otimes\rho_4\otimes\dots\otimes\rho_4\otimes\sigma_x\otimes\sigma_x\otimes\rho_4\otimes\rho_4,$$
	$$\text{and}\quad AA^T = \rho_{00334\dots 00334}.$$
	For $N$ repitions of $ 01234$, the $U_1$ circuit is a multi-control NOT with $2N$ open controls and $2N$ closed controls. Similarly, the $U_2$ circuit has $2N$ $ \sigma_x$ gates. $\Box$
</div>
<p>In Example 3 I once again used the shorthand $\rho_{ijk}=\rho_i\otimes\rho_j\otimes\rho_k$. This example demonstrates just how easy it is to determine the circuits for the block encoding of $A$ for even very large matrices.</p>
<p>What this all means is that if we have some matrix $A$ that is a tensor product of $\rho_j$ terms, then we can find an efficient circuit to block encode it. However, for an arbitrary matrix $A$ it is unlikely to be split into a single term like this. So instead, we split $A$ into a linear combination of terms where each is individually formed by tensor products of the $\rho_j$ terms. Mathematically,
$$A = \sum_{l=1}^{n_l}\alpha_l A_l, \quad A_l = \bigotimes_k\rho_{r_k}$$
where $\alpha_l$ is a coefficient, and $r_k\in\{0,1,2,3,4\}$ is a set that generalizes the indices.</p>
<p>This is useful because now each $A_l$ can be block encoded &ndash; following the methods outlined above &ndash; and implemented into the VQLS routine to find a solution!</p>
<p>While this is a powerful tool for those very specific kinds of matrices, what if our matrix $A$ takes a similar but different form? Can we adapt this technique to once again create efficient circuits? The answer is yes! And that is the subject of the next blog post.</p>
<p><strong>Questions or comments?</strong> ReubenDemi [at] gmail [dot] com</p>
<hr>
<h3 id="references">References</h3>
<p><a id="1">[1]</a>
Harrow, Aram W., Avinatan Hassidim, and Seth Lloyd. &ldquo;Quantum algorithm for linear systems of equations.&rdquo; Physical review letters 103.15 (2009): 150502.</p>
<p><a id="2">[2]</a>
Childs, Andrew M., Robin Kothari, and Rolando D. Somma. &ldquo;Quantum algorithm for systems of linear equations with exponentially improved dependence on precision.&rdquo; SIAM Journal on Computing 46.6 (2017): 1920-1950.</p>
<p><a id="3">[3]</a>
Bravo-Prieto, Carlos, et al. &ldquo;Variational quantum linear solver.&rdquo; Quantum 7 (2023): 1188.</p>
<p><a id="4">[4]</a>
Aaronson, Scott. &ldquo;Read the fine print.&rdquo; Nature Physics 11.4 (2015): 291-293.</p>
<p><a id="5">[5]</a>
Demirdjian, Reuben, Thomas Hogancamp, and Daniel Gunlycke. &ldquo;An Efficient Decomposition of the Carleman Linearized Burgers&rsquo; Equation.&rdquo; arXiv preprint arXiv:2505.00285 (2025).</p>
<p><a id="6">[6]</a>
Liu, Jin-Peng, et al. &ldquo;Efficient quantum algorithm for dissipative nonlinear differential equations.&rdquo; Proceedings of the National Academy of Sciences 118.35 (2021): e2026805118.</p>
<p><a id="7">[7]</a>
A. Gnanasekaran and A. Surana, &ldquo;Efficient Variational Quantum Linear Solver for Structured Sparse Matrices,&rdquo; 2024 IEEE International Conference on Quantum Computing and Engineering (QCE), Montreal, QC, Canada, 2024, pp. 199-210, doi: 10.1109/QCE60285.2024.00033.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
